# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
---
# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
talosVersion: v1.9.2
# renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
kubernetesVersion: v1.32.1

clusterName: kubernetes
endpoint: https://192.168.1.25:6443

clusterPodNets:
  - "172.16.0.0/16"
clusterSvcNets:
  - "172.17.0.0/16"

additionalApiServerCertSans: &sans
  - "192.168.1.25"
  - "127.0.0.1"
additionalMachineCertSans: *sans

# Disable built-in Flannel to use Cilium
cniConfig:
  name: none

nodes:
  - hostname: "bonds"
    ipAddress: "192.168.1.25"
    installDiskSelector:
      model: "QEMU*"
    machineSpec:
      secureboot: false
    nodeLabels:
      nvidia.com/gpu: "present"
      nvidia.com/gpu.model: "4090"
    kernelModules:
      - name: nvidia
      - name: nvidia_uvm
      - name: nvidia_drm
      - name: nvidia_modeset
    schematic:
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/nvidia-container-toolkit-production
            - siderolabs/nonfree-kmod-nvidia-production
            - siderolabs/qemu-guest-agent
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "bc:24:11:58:64:7d"
        dhcp: false
        addresses:
          - "192.168.1.25/24"
        routes:
          - network: "0.0.0.0/0"
            gateway: "192.168.1.1"
        mtu: 1500
        # vip:
        #   ip: "192.168.1.38"
      - interface: wg0
        mtu: 1500
        addresses:
          - 10.100.0.25/24
        wireguard:
          privateKey: ${BONDS_WG_PRIVATE_KEY}
          listenPort: 51821
          peers:
            - publicKey: ${POSEY_WG_PUBLIC_KEY}
              endpoint: ${NAPA_WG_ENDPOINT}
              allowedIPs:
                - 10.100.0.28/32
  # - hostname: "posey"
  #   ipAddress: "10.0.40.28"
  #   installDiskSelector:
  #     model: "KINGSTON SNV2S1000G"
  #   machineSpec:
  #     secureboot: false
  #   nodeLabels:
  #     nvidia.com/gpu: "present"
  #     nvidia.com/gpu.model: "p400"
  #   kernelModules:
  #     - name: nvidia
  #     - name: nvidia_uvm
  #     - name: nvidia_drm
  #     - name: nvidia_modeset
  #   schematic:
  #     customization:
  #       systemExtensions:
  #         officialExtensions:
  #           - siderolabs/nvidia-container-toolkit-production
  #           - siderolabs/nonfree-kmod-nvidia-production
  #   controlPlane: false
  #   networkInterfaces:
  #     - deviceSelector:
  #         hardwareAddr: "c4:62:37:01:8c:cf"
  #       dhcp: false
  #       addresses:
  #         - "10.0.40.28/24"
  #       routes:
  #         - network: "0.0.0.0/0"
  #           gateway: "10.0.40.1"
  #       mtu: 1500
  #     - deviceSelector:
  #         hardwareAddr: c4:62:37:01:8c:ce
  #       ignore: true
  #     - deviceSelector:
  #         hardwareAddr: a8:5e:45:9c:d0:99
  #       ignore: true
  #     - interface: wg0
  #       mtu: 1500
  #       addresses:
  #         - 10.100.0.28/24
  #       wireguard:
  #         privateKey: ${POSEY_WG_PRIVATE_KEY}
  #         listenPort: 51821
  #         peers:
  #           - publicKey: ${BONDS_WG_PUBLIC_KEY}
  #             endpoint: ${APARTMENT_WG_ENDPOINT}
  #             allowedIPs:
  #               - 10.100.0.25/32

# Global patches
patches:
  - "@./patches/global/machine-files.yaml"
  - "@./patches/global/machine-kubelet.yaml"
  - "@./patches/global/machine-network.yaml"
  - "@./patches/global/machine-sysctls.yaml"
  - "@./patches/global/machine-time.yaml"
  - "@./patches/global/machine-install.yaml"

# Controller patches
controlPlane:
  patches:
    - "@./patches/controller/admission-controller-patch.yaml"
    - "@./patches/controller/cluster.yaml"
